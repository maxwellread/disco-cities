{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ea0159",
   "metadata": {},
   "source": [
    "PRODUCE MAIN ALBUM TABLE\n",
    "\n",
    "This code turns out masters database into an SQL-query ready table. This file merges our master database with information gathered from releases and our geocoded studios. Lastly, we merge the coordinates from the geocoder to the urban area boundaries from Kelso et. al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxmo\\Dropbox\\GDS\\Dissertation\\replication\n"
     ]
    }
   ],
   "source": [
    "#%cd path\\to\\\\replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcca8818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SETUP\n",
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "#INPATH = r\"data\\masters_with_coords_v1.csv\"\n",
    "INPATH = r\"data\\masters_with_coords_v3.csv\"\n",
    "OUTPATH = r\"data\\full_table_v2.csv\"\n",
    "ARTIST_INFO_PATH = r\"data\\artists_v1.csv\"\n",
    "URBAN_AREAS_PATH = r\"data\\shapes\\stanford-ua-shapefile\\yk247bg4748.shp\"\n",
    "COORDS_OUTPATH = r\"data\\studios_coords_v1.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73ce59",
   "metadata": {},
   "source": [
    "PROCEEDURE:\n",
    "1. Keep columns master_id, artist_ids, genres, styles, data_quality, year, title, recorded_id, Name, latitude, longitude\n",
    "2. drop duplicates\n",
    "3. drop data_quality < 2 if data_quality ==2 exists for a given master_id\n",
    "4. spatial merge the lat-lon to an urban area\n",
    "5. unnest the columns: artist_ids, genres, styles - rename each to the \n",
    "6. merge artist level information on artist_id renaming columns 'name' as 'artist_name', 'data_quality' as 'artist_info_data_quality'\n",
    "7. save to outpath\n",
    "8. produce a set of unique coordinates, count the number of masters and save the coordinates and the name of the studio to the coordinates path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99790c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['master_id', 'artist_ids', 'genres', 'styles', 'data_quality_x', 'year',\n",
       "       'title', 'release_id', 'recorded_at', 'data_quality_y', 'recorded_id',\n",
       "       'latitude', 'longitude', 'geocoding_method'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "masters = pd.read_csv(INPATH)\n",
    "artists = pd.read_csv(ARTIST_INFO_PATH)\n",
    "urban_areas = gpd.read_file(URBAN_AREAS_PATH)\n",
    "masters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3cb541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Keep specified columns\n",
    "cols_to_keep = ['master_id', 'artist_ids', 'genres', 'styles', 'data_quality_y', 'year', 'title', 'recorded_id', 'latitude', 'longitude', 'geocoding_method']\n",
    "masters = masters[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2973e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Drop duplicates\n",
    "masters = masters.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f131806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Drop data_quality < 2 if data_quality == 2 exists for a given master_id\n",
    "mask = masters.groupby('master_id')['data_quality_y'].transform('max') == 2\n",
    "masters = masters[~((masters['data_quality_y'] < 2) & mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63507b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Spatial merge the lat-lon to an urban area\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    masters,\n",
    "    geometry=[Point(xy) for xy in zip(masters.longitude, masters.latitude)],\n",
    "    crs=urban_areas.crs\n",
    ")\n",
    "masters = gpd.sjoin(gdf, urban_areas, how='left', predicate='intersects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "009404e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Electro' 'Synth-pop' 'Trance' 'Progressive Trance' 'Disco' 'Soft Rock'\n",
      " 'Pop Rock' 'Grindcore' 'Punk' 'Hardcore' 'Crust' 'Goth Rock' 'Hard Rock'\n",
      " 'Heavy Metal' 'Blues Rock' 'Garage Rock' 'Indie Rock' 'Jazz-Rock'\n",
      " 'Prog Rock' 'Reggae' 'Dub' 'Toasting' 'Art Rock' 'Deep House' 'House'\n",
      " 'Alternative Rock' 'Tribal' 'Folk Rock' 'Acoustic' 'Abstract' 'Ambient'\n",
      " 'Experimental' 'Minimal' 'Soundtrack' 'Modern Classical' 'Score'\n",
      " 'New Wave' 'Leftfield' 'Black Metal' 'Field Recording' 'Breaks'\n",
      " 'Psychedelic Rock' 'Breakbeat' 'Industrial' 'Doom Metal' 'Ska' 'Techno'\n",
      " 'IDM' 'Avantgarde' 'Ballad' 'J-pop' 'Downtempo' 'Classic Rock' 'Vocal'\n",
      " 'Glitch' 'EBM' 'Rock & Roll' 'Free Improvisation' 'Spoken Word'\n",
      " 'Ethereal' 'Post Rock' 'Alternative Metal' 'Contemporary R&B' 'Soul' nan\n",
      " 'Goregrind' 'Drum n Bass' 'Symphonic Rock' 'Classical'\n",
      " 'Progressive House' 'Acid Jazz' 'Contemporary' 'Stoner Rock' 'Fusion'\n",
      " 'Drone' 'Progressive Metal' 'Pop Rap' 'Garage House' 'Glam' 'Europop'\n",
      " 'Dream Pop' 'Neo-Classical' 'Dark Ambient' 'Krautrock' 'Lo-Fi'\n",
      " 'Contemporary Jazz' 'Arena Rock' 'Thrash' 'Power Metal' 'Chanson'\n",
      " 'Easy Listening' 'Noise' 'Gothic Metal' 'Modal' 'Southern Rock' 'Funk'\n",
      " 'Death Metal' 'Emo' 'Viking Metal' 'Folk Metal' 'Dub Techno' 'Post-Punk'\n",
      " 'New Age' 'Speed Metal' 'Choral' 'Mathcore' 'Symphonic Metal' 'Math Rock'\n",
      " 'Free Jazz' 'Theme' 'Indie Pop' 'Space Rock' 'Boom Bap'\n",
      " 'Hardcore Hip-Hop' 'Acid Rock' 'Shoegaze' 'Sludge Metal' 'Country Rock'\n",
      " 'Conscious' 'Baroque Pop' 'Hard Trance' 'Happy Hardcore' 'Trip Hop'\n",
      " 'Crossover thrash' 'Neo-Romantic' 'Parody' 'Euro House'\n",
      " 'Indian Classical' 'Hindustani' 'Baroque' 'Folk' 'Darkwave' 'UK Garage'\n",
      " 'Power Pop' 'Neofolk' 'Melodic Death Metal' 'Italo House' 'Comedy'\n",
      " 'Britpop' 'Industrial Metal' 'Italodance' 'Hip-House' 'Future Jazz'\n",
      " 'Instrumental' 'Hip Hop' 'Acid' 'Funk Metal' 'Noise Rock' 'Eurodance'\n",
      " 'Lounge' 'Doo Wop' 'Post-Hardcore' 'Psychedelic' 'Swing' 'Jangle Pop'\n",
      " 'Big Beat' 'Gospel' 'Rhythm & Blues' 'Mambo' 'Schlager' 'AOR' 'Jungle'\n",
      " 'Italo-Disco' 'Smooth Jazz' 'Ethno-pop' 'Broken Beat' 'Bleep'\n",
      " 'Latin Jazz' 'New Beat' 'Rockabilly' 'Acid House' 'Roots Reggae'\n",
      " 'Reggae-Pop' 'Tech House' 'Jazzdance' 'Louisiana Blues' 'Grunge' 'Celtic'\n",
      " 'Neo Soul' 'Psychobilly' 'Jazz-Funk' 'Cabaret' 'P.Funk' 'Post-Metal'\n",
      " 'Country' 'Space-Age' 'Monolog' 'Novelty' 'Piano Blues' 'Dance-pop'\n",
      " 'RnB/Swing' 'Musical' 'Electroclash' 'Ambient House' 'Religious'\n",
      " 'Groove Metal' 'Medieval' 'Renaissance' 'Poetry' 'Soul-Jazz' 'Boogie'\n",
      " 'Horror Rock' 'Synthwave' 'Anison' 'Rocksteady' 'No Wave' 'Post Bop'\n",
      " 'Concert Film' 'Future Pop' 'Berlin-School' 'Hard Bop' 'Post-Modern'\n",
      " 'Illbient' 'Beat' 'Ragga HipHop' 'Bop' 'Cool Jazz' 'Turntablism'\n",
      " 'Coldwave' 'Electroacoustic' 'Dark Jazz' 'Yé-Yé' 'Pornogrind'\n",
      " 'Power Electronics' 'Big Band' 'Freestyle' 'Power Violence' 'Holiday'\n",
      " 'Nu Metal' 'Hardstyle' 'Free Funk' 'Interview' 'Sound Poetry' 'Modern'\n",
      " 'Dark Electro' 'Funeral Doom Metal' 'Horrorcore'\n",
      " 'Atmospheric Black Metal' 'Gangsta' 'Opera' 'Metalcore'\n",
      " 'Avant-garde Jazz' 'African' 'Pop Punk' 'Breakcore' 'Military' 'Samba'\n",
      " 'Batucada' 'Brass Band' 'Goa Trance' 'Bossanova' 'Salsa' 'Merengue'\n",
      " 'Afro-Cuban' 'Afrobeat' 'Electric Blues' 'Flamenco' 'Music Hall'\n",
      " 'Klezmer' 'Go-Go' 'Romantic' 'New Jack Swing' 'G-Funk' 'Nu-Disco'\n",
      " 'Cut-up/DJ' 'Modern Electric Blues' 'Technical Death Metal'\n",
      " 'Minneapolis Sound' 'Hi NRG' 'Mod' 'Hard House' 'Bubblegum'\n",
      " 'Melodic Hardcore' 'Slowcore' 'Bouncy Techno' 'Thug Rap' 'Reggaeton'\n",
      " 'Latin' 'Afro-Cuban Jazz' 'Minimal Techno' 'Progressive Breaks'\n",
      " 'Jazzy Hip-Hop' 'Dancehall' 'Radioplay' 'Għana' 'Highlife' 'Deathrock'\n",
      " 'Dialogue' 'Oi' 'Fado' 'Kayōkyoku' 'Country Blues' 'Speed Garage'\n",
      " 'Bass Music' 'Gabber' 'Surf' 'Synthpunk' 'Euro-Disco' 'Rock Opera'\n",
      " 'Musique Concrète' 'Zouk' 'Educational' 'Cajun' 'Calypso' 'Tango' 'Crunk'\n",
      " 'Boogaloo' 'French House' 'Rhythmic Noise' 'Balearic' 'Harmonica Blues'\n",
      " 'Ragtime' 'Depressive Black Metal' 'Chicago Blues' 'Tribal House'\n",
      " 'Hands Up' 'Psy-Trance' 'Tech Trance' 'Ballroom' 'Hyphy' 'Pub Rock'\n",
      " 'Grime' 'Bossa Nova' 'Levenslied' 'Ragga' 'Cape Jazz' 'Delta Blues'\n",
      " 'Hard Beat' 'Beatbox' 'Dixieland' 'Appalachian Music' 'Electro House'\n",
      " 'Speech' 'Swingbeat' 'Lovers Rock' 'Cha-Cha' 'Eurobeat' 'Chiptune'\n",
      " 'Latin Pop' 'City Pop' 'Texas Blues' 'Jump Blues' 'Bayou Funk'\n",
      " 'Swamp Pop' 'Rumba' 'Bounce' 'Dubstep' 'Guaguancó' 'Bolero' 'Cumbia'\n",
      " 'Trap' 'Political' 'Descarga' 'Deathcore' 'MPB' 'Forró' 'Gamelan'\n",
      " 'Sound Art' 'Zydeco' 'Anarcho-Punk' 'Freetekno' 'Alt-Pop' 'NDW'\n",
      " 'Cloud Rap' 'East Coast Blues' 'Pachanga' 'Ranchera' 'Mbalax'\n",
      " 'Midwest Emo' 'Sound Collage' 'Cubano' 'Raï' 'Arabic Pop' 'Trova' 'Son'\n",
      " 'Danzon' 'Guajira' 'Serial' 'Britcore' 'Qawwali' 'Sunshine Pop'\n",
      " 'Public Broadcast' 'Occult' 'Impressionist' 'Miami Bass' 'Gypsy Jazz'\n",
      " 'Glitch Hop' 'Steel Band' 'Bhangra' 'Erotic' 'Nordic' 'Piedmont Blues'\n",
      " 'Special Effects' 'Bluegrass' 'Ghetto' 'Makina' 'Aboriginal' 'Honky Tonk'\n",
      " 'Ghettotech' 'Lambada' 'J-Rock' 'Video Game Music' 'Audiobook'\n",
      " 'Jumpstyle' 'Sonero' 'Bassline' 'Early' 'Memphis Rap' 'Screamo'\n",
      " 'UK Street Soul' 'Dub Poetry' 'Lento Violento' 'Norteño' 'Mariachi'\n",
      " 'Exotica' 'Sermon' 'Ghetto House' 'Neopagan' 'Bomba' 'Organ' 'Junkanoo'\n",
      " 'Romani' 'Soca' 'Screw' 'Boogie Woogie' 'Post-Grunge' 'Morna' 'Bollywood'\n",
      " 'Education' 'Yemenite Jewish' 'Mizrahi' 'Sephardic' 'Twist' 'Skiffle'\n",
      " 'Hawaiian' 'Bachata' 'Sea Shanties' 'DJ Battle Tool' 'Pacific' 'Story'\n",
      " 'Health-Fitness' 'Tejano' 'Plunderphonics' 'Kuduro' 'Griot' 'Compas'\n",
      " 'Kolo' 'Desert Blues' 'UK Funky' 'Memphis Blues' 'Bakersfield Sound'\n",
      " 'Vallenato' 'Éntekhno' \"Min'yō\" 'Marches' 'Carnatic' 'Overtone Singing'\n",
      " 'Noisecore' 'Operetta' 'Conjunto' 'Unblack Metal' 'Nursery Rhymes'\n",
      " 'Zarzuela' 'Light Music' 'Spirituals' 'Nueva Cancion' 'Movie Effects'\n",
      " 'Gagaku' 'Son Montuno' 'Plena' 'Marimba' 'Electro Swing' 'Guaracha'\n",
      " 'Catalan Music' 'Disco Polo' 'Axé' 'Music Video' 'Oratorio' 'Twelve-tone'\n",
      " 'Volksmusik' 'Ballet' 'Mugham' 'Soukous' 'Kaseko' 'Mento' 'Deep Techno'\n",
      " 'Laïkó' 'Low Bap' 'Népzene' 'Karaoke' 'Western Swing' 'Sámi Music'\n",
      " 'Pipe & Drum' 'Choro' 'Baião' 'Dungeon Synth' 'Technical'\n",
      " 'Progressive Bluegrass' 'Jibaro' 'Chinese Classical' 'Hillbilly'\n",
      " 'Reggae Gospel' 'Rebetiko' 'Hypnagogic pop' 'Galician Traditional'\n",
      " 'Polka' 'Candombe' 'Basque Music' 'Blackgaze' 'Snap' 'Beguine'\n",
      " 'Andean Music' 'Occitan' 'Persian Classical' 'Sertanejo' 'Guarania'\n",
      " 'Charanga' 'K-pop' 'Néo Kyma' 'Huayno' 'Cretan' 'Rune Singing'\n",
      " 'Nueva Trova' 'K-Rock' 'Speedcore' 'Andalusian Classical' 'Vaudeville'\n",
      " 'Skweee' 'Therapy' 'Canzone Napoletana' 'Barbershop' 'Enka'\n",
      " 'Deconstructed Club' 'Phonk' 'Stride' 'Hill Country Blues' 'Séga' 'Copla'\n",
      " 'Cuatro' 'Nintendocore' 'Hiplife' 'Ottoman Classical' 'Timba'\n",
      " 'Villancicos' 'Quechua' 'Carimbó' 'Chacarera' 'Pasodoble' 'Samba-Canção'\n",
      " 'Group Sounds' 'Persian Pop' 'Banda' 'Microhouse' 'Promotional' 'Corrido'\n",
      " 'Mouth Music' 'Gnawa' 'Milonga' 'Bengali Music' 'Mandopop' 'Piobaireachd'\n",
      " 'Dabke' 'Bitpop' 'Indo-Pop' 'Cobla' 'Música Criolla' 'Shibuya-Kei'\n",
      " 'Maloya' 'Keroncong' 'Drill' 'Funaná' 'Liscio' 'Chillwave' 'Musette'\n",
      " 'Gaita' 'Waiata' 'Caipira' 'Rapso' 'Jug Band' 'Tropical House' 'Chamamé'\n",
      " 'J-Core' 'Public Service Announcement' 'Cantopop' 'Chutney' 'Salegy'\n",
      " 'Porro' 'Favela Funk' 'Joropo' 'Guggenmusik' 'Jota' 'Seresta'\n",
      " 'Hokkien Pop' 'Cambodian Classical' 'Trallalero' 'Harsh Noise Wall'\n",
      " 'Zamba' 'Ghazal' 'Manila Sound' 'Philippine Classical' 'Nhạc Vàng'\n",
      " 'Future Bass' 'Shaabi' 'Aguinaldo' 'Hyperpop' 'Zemer Ivri' 'Gqom'\n",
      " 'Gwo Ka' 'Luk Thung' 'Mo Lam' 'Thai Classical' 'Vaporwave' 'Cantorial'\n",
      " 'Neo Trance' 'Kwaito' 'Beatdown' 'Honkyoku' 'Hyper Techno' 'Antifolk'\n",
      " 'Korean Court Music' 'Marcha Carnavalesca' 'Witch House' 'Filk'\n",
      " 'Hard Techno' 'Lao Music' 'Neo-Classical Metal' 'Baltimore Club'\n",
      " 'Sean-nós' 'Frevo' 'Lullaby' 'Jersey Club' 'Dangdut' 'Break-In']\n"
     ]
    }
   ],
   "source": [
    "# 5. Unnest the columns: artist_id, genres, styles\n",
    "import ast\n",
    "for col in ['artist_ids', 'genres', 'styles']:\n",
    "    masters[col] = masters[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "masters = masters.explode('artist_ids')\n",
    "masters = masters.explode('genres')\n",
    "masters = masters.explode('styles')\n",
    "\n",
    "# Rename unnested columns to singular\n",
    "masters = masters.rename(columns={\n",
    "    'artist_ids': 'artist_id',\n",
    "    'genres': 'genre',\n",
    "    'styles': 'style'\n",
    "})\n",
    "\n",
    "print(masters['style'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43255700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "Rock                      274127\n",
      "Classical                 129473\n",
      "Pop                       107507\n",
      "Electronic                 96984\n",
      "Jazz                       91640\n",
      "Folk, World, & Country     66654\n",
      "Funk / Soul                57033\n",
      "Stage & Screen             26789\n",
      "Hip Hop                    23606\n",
      "Blues                      20606\n",
      "Latin                      19665\n",
      "Reggae                     17413\n",
      "Non-Music                   8869\n",
      "Children's                  3755\n",
      "Brass & Military            1640\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(masters['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c3db5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Merge artist level information on artist_id, renaming columns\n",
    "artists = artists.rename(columns={'name': 'artist_name', 'data_quality': 'artist_info_data_quality'})\n",
    "# Ensure both artist_id columns are of the same type (string)\n",
    "masters['artist_id'] = masters['artist_id'].astype(str)\n",
    "artists['artist_id'] = artists['artist_id'].astype(str)\n",
    "masters = masters.merge(artists, left_on='artist_id', right_on='artist_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f33450f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "masters = masters.rename(columns={\n",
    "    'Name': 'studio_name',\n",
    "    'name_conve': 'city',\n",
    "    'ISO_CC': 'ctry_code',\n",
    "    'max_pop_al': 'est_2010_population'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f5b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the first year each style appears\n",
    "first_year_per_style = masters.groupby('style')['year'].min()\n",
    "\n",
    "# Create new_style_1 column: 1 if row's style's first year and style match, else 0\n",
    "masters['new_style_1'] = masters.apply(\n",
    "    lambda row: 1 if pd.notna(row['style']) and row['year'] == first_year_per_style[row['style']] else 0,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b40e78f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 cities by % new style:\n",
      "           total_masters  new_style_count  pct_new_style\n",
      "city                                                    \n",
      "Vienna              1751              748       0.427184\n",
      "Stuttgart           1019              278       0.272816\n",
      "Munich              1392              363       0.260776\n",
      "Kingston1           4817             1189       0.246834\n",
      "Berlin              4551              961       0.211162\n",
      "Dresden              551              114       0.206897\n",
      "Koln                 863              153       0.177289\n",
      "Sao Paolo            558               98       0.175627\n",
      "Montreal            1623              277       0.170672\n",
      "The Hague            668              114       0.170659\n",
      "Amsterdam           1862              306       0.164339\n",
      "Antwerpen            526               82       0.155894\n",
      "Bologna              523               73       0.139579\n",
      "Budapest            1194              160       0.134003\n",
      "Dallas               609               79       0.129721\n",
      "London2            30019             3414       0.113728\n",
      "Hamburg             2155              245       0.113689\n",
      "Warsaw               743               82       0.110363\n",
      "Paris               9615             1061       0.110348\n",
      "Boston              2116              207       0.097826\n",
      "\n",
      "Bottom 20 cities by % new style:\n",
      "              total_masters  new_style_count  pct_new_style\n",
      "city                                                       \n",
      "Oslo                   1106                7       0.006329\n",
      "Irvine                  761               11       0.014455\n",
      "Paterson               1295               21       0.016216\n",
      "Alexandria2             533               10       0.018762\n",
      "Athens2                2073               44       0.021225\n",
      "Pasadena2              7226              169       0.023388\n",
      "Helsinki               2732               64       0.023426\n",
      "Osaka                   676               16       0.023669\n",
      "Goteborg                710               17       0.023944\n",
      "Melbourne2             2958               71       0.024003\n",
      "Newark                 1440               35       0.024306\n",
      "Athens1                 602               15       0.024917\n",
      "Nashville              5870              148       0.025213\n",
      "Seattle                1550               40       0.025806\n",
      "Atlanta                1283               35       0.027280\n",
      "Buenos Aires            523               15       0.028681\n",
      "Sydney1                2296               70       0.030488\n",
      "Memphis                1165               38       0.032618\n",
      "Los Angeles1          24331              796       0.032715\n",
      "Vancouver2              958               32       0.033403\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of releases that are a new style per city\n",
    "city_new_style = masters.groupby('city').agg(\n",
    "    total_masters=('master_id', 'nunique'),\n",
    "    new_style_count=('new_style_1', 'sum')\n",
    ")\n",
    "city_new_style['pct_new_style'] = city_new_style['new_style_count'] / city_new_style['total_masters']\n",
    "\n",
    "# Filter cities with more than 500 masters\n",
    "city_filtered = city_new_style[city_new_style['total_masters'] > 500]\n",
    "\n",
    "# Top 20 \n",
    "print(\"Top 20 cities by % new style:\")\n",
    "print(city_filtered.sort_values('pct_new_style', ascending=False).head(20))\n",
    "\n",
    "# Bottom 20\n",
    "print(\"\\nBottom 20 cities by % new style:\")\n",
    "print(city_filtered.sort_values('pct_new_style', ascending=True).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfb314cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# For each master_id, get all style combinations (sorted tuples, size 2)\n",
    "def get_style_combos(styles):\n",
    "    styles = list(set(styles))  # remove duplicates\n",
    "    return list(combinations(sorted(styles), 2))\n",
    "\n",
    "master_styles = masters.groupby('master_id')['style'].apply(list)\n",
    "\n",
    "combo_rows = []\n",
    "for master_id, styles in master_styles.items():\n",
    "    combos = get_style_combos(styles)\n",
    "    year = masters.loc[masters['master_id'] == master_id, 'year'].iloc[0]\n",
    "    for combo in combos:\n",
    "        combo_rows.append({'master_id': master_id, 'style_combo': combo, 'year': year})\n",
    "\n",
    "combo_df = pd.DataFrame(combo_rows)\n",
    "\n",
    "first_year_per_combo = combo_df.groupby('style_combo')['year'].min()\n",
    "\n",
    "# For each master_id, count how many of its combos are novel (first year for that combo)\n",
    "def count_novel_combos(row):\n",
    "    combos = get_style_combos(master_styles[row['master_id']])\n",
    "    year = row['year']\n",
    "    return sum(year == first_year_per_combo[combo] for combo in combos)\n",
    "\n",
    "masters['novel_style_combo_count'] = masters.apply(count_novel_combos, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe18251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 cities by average novel_style_combo_count:\n",
      "             city  novel_style_combo_avg  master_count\n",
      "526      Montreal               2.938042          1623\n",
      "835         Tokyo               1.506270          5212\n",
      "828     The Hague               1.384760           668\n",
      "133  Buenos Aires               1.203418           523\n",
      "168       Chicago               0.976638          4248\n",
      "48         Austin               0.846315          1338\n",
      "631  Philadelphia               0.821647          2342\n",
      "78       Berkeley               0.818477          1224\n",
      "204        Dallas               0.787384           609\n",
      "884        Vienna               0.782947          1751\n",
      "328       Houston               0.746082           785\n",
      "593         Osaka               0.734827           676\n",
      "398          Koln               0.718800           863\n",
      "558   New Orleans               0.708333           765\n",
      "578       Oakland               0.696251          1628\n",
      "595          Oslo               0.693966          1106\n",
      "718     San Diego               0.676275           443\n",
      "741     Sao Paolo               0.658829           558\n",
      "451     Ljubljana               0.624413           476\n",
      "214       Detroit               0.605230          1145\n",
      "\n",
      "Bottom 20 cities by average novel_style_combo_count:\n",
      "            city  novel_style_combo_avg  master_count\n",
      "219      Dresden               0.059922           551\n",
      "882   Versailles               0.110783           446\n",
      "341       Irvine               0.112988           761\n",
      "651    Portland2               0.120000           582\n",
      "13   Alexandria2               0.134240           533\n",
      "449   Liverpool2               0.137148           470\n",
      "245     Evanston               0.137361          1078\n",
      "90   Birmingham2               0.142202           528\n",
      "881       Verona               0.148191           427\n",
      "221      Dublin2               0.150581           615\n",
      "39       Athens1               0.151662           602\n",
      "232    Edinburgh               0.157486           459\n",
      "721    San Jose3               0.161566           510\n",
      "789     Stamford               0.179609           537\n",
      "483        Malmo               0.184524           415\n",
      "750      Seattle               0.185203          1550\n",
      "433      Leipzig               0.185845           428\n",
      "306      Hamburg               0.204229          2155\n",
      "550    Nashville               0.207441          5870\n",
      "500   Melbourne2               0.209156          2958\n"
     ]
    }
   ],
   "source": [
    "# Calculate average novel_style_combo_count per city\n",
    "city_novel_combo = masters.groupby('city').agg(\n",
    "    novel_style_combo_avg=('novel_style_combo_count', 'mean'),\n",
    "    master_count=('master_id', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Filter cities with at least 400 masters\n",
    "city_novel_combo = city_novel_combo[city_novel_combo['master_count'] >= 400]\n",
    "\n",
    "# Top 20 cities\n",
    "top20 = city_novel_combo.sort_values('novel_style_combo_avg', ascending=False).head(20)\n",
    "print(\"Top 20 cities by average novel_style_combo_count:\")\n",
    "print(top20)\n",
    "\n",
    "# Bottom 20 cities\n",
    "bottom20 = city_novel_combo.sort_values('novel_style_combo_avg', ascending=True).head(20)\n",
    "print(\"\\nBottom 20 cities by average novel_style_combo_count:\")\n",
    "print(bottom20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d53c2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE CITY COUNTS - USEFUL TO HAVE\n",
    "city_counts = masters.groupby('city')['master_id'].nunique().reset_index(name='unique_master_count')\n",
    "city_counts.to_csv(r\"data\\explorations\\city_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b45d73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Save to outpath, dorp bounding box and urban area columns if present\n",
    "cols_to_drop = [\n",
    "    'min_bb_xmi', 'max_bb_xmi', 'min_bb_xma', 'max_bb_yma',\n",
    "    'min_bb_ymi', 'max_bb_ymi', 'min_bb_yma', 'max_bb_yma',\n",
    "    'mean_bb_xc', 'mean_bb_yc',\n",
    "    'index_right', 'name_conve', 'max_pop_al', 'max_pop_20', 'max_pop_50',\n",
    "    'max_pop_30', 'max_pop_31', 'max_natsca', 'min_areakm', 'max_areakm',\n",
    "    'min_areami', 'max_areami', 'min_perkm', 'max_perkm', 'min_permi', 'max_permi'\n",
    "]\n",
    "masters = masters.drop(columns=[col for col in cols_to_drop if col in masters.columns])\n",
    "\n",
    "masters.to_csv(OUTPATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fb3f5c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 8. Produce a set of unique coordinates, count the number of masters and save\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m studio_coords \u001b[38;5;241m=\u001b[39m masters\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaster_count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m studio_coords\u001b[38;5;241m.\u001b[39mto_csv(COORDS_OUTPATH, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\maxmo\\anaconda3\\envs\\GRL_env\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   9184\u001b[0m     obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9185\u001b[0m     keys\u001b[38;5;241m=\u001b[39mby,\n\u001b[0;32m   9186\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   9187\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   9188\u001b[0m     as_index\u001b[38;5;241m=\u001b[39mas_index,\n\u001b[0;32m   9189\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   9190\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   9191\u001b[0m     observed\u001b[38;5;241m=\u001b[39mobserved,\n\u001b[0;32m   9192\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[0;32m   9193\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\maxmo\\anaconda3\\envs\\GRL_env\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m get_grouper(\n\u001b[0;32m   1330\u001b[0m         obj,\n\u001b[0;32m   1331\u001b[0m         keys,\n\u001b[0;32m   1332\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   1333\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   1334\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m   1335\u001b[0m         observed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default \u001b[38;5;28;01melse\u001b[39;00m observed,\n\u001b[0;32m   1336\u001b[0m         dropna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna,\n\u001b[0;32m   1337\u001b[0m     )\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\maxmo\\anaconda3\\envs\\GRL_env\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Name'"
     ]
    }
   ],
   "source": [
    "# 8. Produce a set of unique coordinates, count the number of masters and save\n",
    "studio_coords = masters.groupby(['Name', 'latitude', 'longitude']).size().reset_index(name='master_count')\n",
    "studio_coords.to_csv(COORDS_OUTPATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fb43f9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GRL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
